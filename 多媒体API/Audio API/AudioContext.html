<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AudioContext</title>
    <style>
      body {
        padding: 100px;
      }
    </style>
  </head>
  <body>
    <h1>AudioContext</h1>
    <hr />
    <button>Make white noise 发出白噪音</button>
    <script>
      {
        class MuAudio {
          constructor() {
            this.ac = null;
            this.init();
          }
          init() {
            try {
              window.AudioContext = window.AudioContext || window.webkitAudioContext;
              this.ac = new AudioContext();
            } catch (e) {
              alert("请更新至最新版的 Chrome 或者 Firefox");
              throw "请更新至最新版的 Chrome 或者 Firefox";
            }
          }
        }
      }
      {
        const button = document.querySelector("button");

        let ac;

        // 立体声2, 2.1
        let channels = 2.0;

        function init() {
          ac = new (window.AudioContext || window.webkitAudioContext)();
        }

        button.onclick = () => {
          if (!ac) {
            init();
          }

          // 以AudioContext的采样率创建一个空的两秒立体声缓冲区
          const frameCount = ac.sampleRate * 2.0;

          const buffer = new AudioBuffer({
            numberOfChannels: channels,
            length: frameCount,
            sampleRate: ac.sampleRate,
          });

          //用白噪声填充缓冲区；
          //只是-1.0和1.0之间的随机值
          for (let channel = 0; channel < channels; channel++) {
            // This gives us the actual array that contains the data
            const nowBuffering = buffer.getChannelData(channel);
            for (let i = 0; i < frameCount; i++) {
              // Math.random() is in [0; 1.0]
              // audio needs to be in [-1.0; 1.0]
              nowBuffering[i] = Math.random() * 2 - 1;
            }
          }

          //获取AudioBufferSourceNode。
          //这是要播放AudioBuffer时要使用的AudioNode
          const source = ac.createBufferSource();
          // Set the buffer in the AudioBufferSourceNode
          source.buffer = buffer;
          // Connect the AudioBufferSourceNode to the
          // destination so we can hear the sound
          source.connect(ac.destination);
          // start the source playing
          source.start();

          source.onended = () => {
            console.log("白噪音结束。");
          };
        };
      }

      {
        const video = document.createElement("video");
        const ac = new (window.AudioContext || window.webkitAudioContext)();
        const analyser = ac.createAnalyser();

        // 先加载视频文件
        video.src = "./media/202107.mp4";

        video.addEventListener("loadedmetadata", function () {
          // 当视频元数据加载完成后，连接AnalyserNode
          analyser.connect(ac.destination);

          // 获取音频数据的频率和通道数
          const bufferLength = analyser.frequencyBinCount;
          const buffer = new Uint8Array(bufferLength);

          //  console.log(ac.destination, bufferLength, buffer);

          // 使用requestAnimationFrame确保音频采样率与系统时间同步
          requestAnimationFrame(function update() {
            analyser.getByteFrequencyData(buffer);
            // 使用傅里叶变换获取频率数据后，可以处理每个频率值
            for (let i = 0; i < bufferLength; i++) {
              console.log(i, buffer[i]);
            }
            // 每一帧更新时都会调用update方法，因此可以在此继续处理其他音频数据
            // requestAnimationFrame(update);
          });
        });
      }
    </script>
  </body>
</html>
